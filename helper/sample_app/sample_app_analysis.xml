<?xml version="1.0" encoding="UTF-8"?>

<!-- ==================================================== -->
<!--            Jeyzer Analyzer configuration             -->
<!-- ==================================================== -->

<!--   Available states : production, draft, generic, disabled -->
<analysis application_type="Sample" application_id="${JEYZER_TARGET_NAME}" state="disabled">

	<!-- Context information -->
	<context desc="${JEYZER_TARGET_DESCRIPTION}" issuer="${JEYZER_TARGET_ISSUER}"/>

	<!-- Discovery mode. If disabled, discovery rules won't be loaded. -->
	<discovery_mode enabled="false"/>
	
	<!-- Dependency sets. Referenced in the analysis patterns and monitoring rules -->
	<dependencies>
		<set id="base-shared-deps" profiles="jboss, spring, hibernate, c3p0, oracle, guava, guice, slf4j, log4j, jeyzer, java"/>
	</dependencies>
	
		<!-- Analysis patterns. Load order : top to bottom. Pattern rules of the top pattern set apply first. Dynamic patterns are loaded at last -->
	<patterns>
	
		<!-- Applicative patterns. Local path or remote url (http, https, ftp) -->
		<pattern_set file="${JEYZER_BASE_MASTER_PROFILES_DIR}/${JEYZER_TARGET_PROFILE}/analysis/patterns.xml"/>

		<!-- Repository patterns, either local or remote, loaded as per the dependency declaration order -->
		<pattern_sets files="repo://base/@@base-shared-deps@@"/>
		
		<!-- Repository patterns, either local or remote, loaded as per the process jar path declaration order (JZR recording) -->
		<!-- Declared_repository_only indicates if the loading is limited to jars which contain the Jeyzer Repository attribute. In such case, the patterns will be loaded from the given repository -->
		<!--   Otherwise, the patterns scanning of all repositories will be achieved to load the appropriate shared profile if any (extra cost) -->
		<dynamic_pattern_sets declared_repository_only="false"/>
	
	</patterns>

	<!-- JZR Report configuration -->
	<report report_config_file="${JEYZER_BASE_MASTER_PROFILES_DIR}/${JEYZER_TARGET_PROFILE}/analysis/report/report.xml"/>

	<!-- Refresh period in sec -->
	<replay enabled="${JEYZER_ANALYZER_REPLAY_ENABLED}" refresh_period="${JEYZER_GRAPH_REFRESH_PERIOD}" output_directory="${JEYZER_OUTPUT_DIR}/analysis">
		<!-- Action graph player -->
		<function_graph_player graph_config_file="${JEYZER_ANALYZER_CONFIG_DIR}/graph/player/function_graph_player.xml"/>
	</replay>

	<!-- JZR Report distribution -->
	<!-- Event threshold is applied if any monitoring sheet is displaying an event of same category or higher. Possible values ares : INFO, WARNING, CRITICAL -->
	<notification threshold="CRITICAL">
		<!-- recipients is a comma separated list of emails -->
		<mail mail_enabled="${JEYZER_ANALYZER_TEAM_EMAIL_ENABLED}" setup="${JEYZER_ANALYZER_CONFIG_DIR}/mail/mail.properties" recipients="target-people@domain.org" subject="${JEYZER_TARGET_PROFILE} JZR report generated">
			<template directory="${JEYZER_ANALYZER_CONFIG_DIR}/notification/mail" name="mail_content_template.vm"/>
		</mail>
	</notification>

	<!-- Recording configuration -->
	<!-- File is optional and must refer to a zip or gz file name -->
	<recording period="${JEYZER_RECORD_PERIOD}" directory="${JEYZER_RECORD_DIRECTORY}" file="${JEYZER_RECORD_FILE}">
	
		<translators>	
	
			<!-- Optional uncompress -->
			<translator type="compression" translator_config_file="${JEYZER_ANALYZER_CONFIG_DIR}/translators/compression/uncompress.xml"/>	
	
			<!-- Optional JFR -->
			<translator type="jfr" translator_config_file="${JEYZER_ANALYZER_CONFIG_DIR}/translators/jfr/jfr_uncompress.xml"/>
	
			<!-- Optional decryption -->
			<!-- translator type="jzr_security" translator_config_file="${JEYZER_ANALYZER_CONFIG_DIR}/translators/security/decryption.xml"/-->

			<!-- Obfuscation -->
			<!-- translator type="obfuscation" translator_config_file="${JEYZER_ANALYZER_CONFIG_DIR}/translators/obfuscation/deobfuscation.xml"/-->

		</translators>
		
		<file_patterns>
		
			<!-- Jeyzer file name pattern : time stamp is taken out from file name as well as the time zone. -->
			<!-- File name pattern is snap-<time-zone-origin : p or c or jzr>-<date format with regional time zone>.jzr  -->
		    <file_jzr_pattern/>	
		
			<!-- Time stamp file name pattern : time stamp is taken out from file name -->
			<!-- For a same suffix and prefix, the pattern declaration order is important : put the largest date format first -->
			<!-- ex : thread-dump-<date format>.txt -->
			<!-- date format must follow java date pattern : http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html-->
			<file_timestamp_pattern pattern="thread-dump-&lt;yyyy-MM-dd---HH-mm-ss-SSS-z&gt;.txt"/>			
			<file_timestamp_pattern pattern="thread-dump-&lt;yyyy-MM-dd---HH-mm-ss&gt;.txt"/>
			<file_timestamp_pattern pattern="thread-dump-&lt;yyyy-MM-dd--HH-mm-ss&gt;.out"/>
			<!-- Unix date command output    	 td-Sun Jul  1 12_16_06 UTC 2018.txt -->
			<file_timestamp_pattern pattern="td-&lt;EEE MMM dd HH_mm_ss z yyyy&gt;.txt"/>
			<!-- IBM core. Suffix is not readable, ignore it. Example : javacore.20141215.155840.26463.0014.txt -->
			<file_timestamp_pattern pattern="javacore.&lt;yyyyMMdd.HHmmss&gt;.26463.0001.txt" ignoreSuffix="true"/>
			  
			<!-- Regular expression file name pattern : time stamp is taken out from file last modified by attribute -->
			<file_regex_pattern     pattern="\.dmp$"/>
			<file_regex_pattern     pattern="\.jstack$"/>
			<file_regex_pattern     pattern="\.txt$"/>
			<file_regex_pattern     pattern="\.dump$"/>
			<file_regex_pattern     pattern="\.tdump$"/>
			<file_regex_pattern     pattern="\.out$"/>
			<file_regex_pattern     pattern="\.tda$"/>
			
			<!-- JMC can generate periodic thread dumps -->
			<file_regex_pattern     pattern="\.jfr$"/>
			
		</file_patterns>
		
	</recording>

	<!-- Thread stack configuration -->
	<thread_stack>
	
		<!-- Stack discard pre-filters -->
		<!--  Permits to exclude the majority of stacks of no interest --> 
		<!--  Analysis profiles will do the rest -->
		<!--  If you know well your application, go for the known_size_strategy --> 
		<!--  Tip : Use the profile tuning to determine it manually or check the Sheet session details to get what got automatically discarded -->
		<analysis_prefilter>

			<!-- Discard ALL stacks below the stack size -->
			<stack_size_interest>
			
				<!-- Size strategy : auto or known or master_profile_state_dependent  -->
				<!--  master_profile_state_dependent : strategy will be auto if master profile has the generic state -->
				<strategy type="master_profile_state_dependent" >
				 
					<!-- Determine automatically the interest size based on the Wait and Timed_Waiting threads -->
					<auto_size_strategy>
						<!-- Set the size once the scan_coverage percentage of the wait/timed_waiting stacks are found in a set of representative snapshot samples -->
						<!-- Snapshot samples are the - taken randomly - ones which contain the less threads so the less active ones -->
						<!-- Snapshot samples must represent at minimum the snapshot_sample_percentage % of the recording to be representative. --> 
						<!-- Default/recommended is 5% (10 => 200 snapshots, period 30 sec => 100 minutes minimum) -->
						<!-- If below snapshot_sample_percentage %, the default_size is taken. default_size should be very low value -->
						<!-- stop_if_active_found : as soon as active threads are encountered with same stack size, stop the scan_coverage and retain the reached size -->
						<!--                        unless your application is fully asynchronous, prefer the activation of the keep_stacks / running -->
						<scan_coverage snapshot_samples="10" snapshot_sample_percentage="30" percentage="98" stop_if_active_found="false" default_size="1"/>
					</auto_size_strategy>
				
					<!-- Interest size is known up front -->
					<known_size_strategy min="15"/>
				
				</strategy>
				
				<!-- In the discard all, do keep particular stacks as follow : -->
				<keep_stacks running="true" locked="true"/>
				
			</stack_size_interest>
						
		</analysis_prefilter>
	
		<!-- Log unidentified stacks (unknown function, operation or executor) -->
		<!--   order by file : stacks may appear multiple times.               --> 
		<!--            frequency : each stack is printed only once            -->
		<ufo generation_enabled="true" zip_output_dir="${JEYZER_OUTPUT_DIR}/analysis" order_by="frequency"/>

		<!-- write all discarded stack traces into ignored-stacks.zip -->
		<ignored_stacks generation_enabled="false" zip_output_dir="${JEYZER_OUTPUT_DIR}/analysis"/>
		
		<!-- Stack ordering : recording (natural one), thread_id, thread_name -->
		<!-- This will influence all the analysis and therefore the report display -->
		<sorting key="thread_name"/>
		
	</thread_stack>
	
	<!-- Time zones -->
	<!--   Ids below can be overridden through the Jeyzer web interface -->
	<time_zones>
	
		<!-- Default recording time zone if not available in the recording. Optional -->
		<recording_time_zone id="${JEYZER_RECORDING_TIME_ZONE_ID}"/>
		
		<!-- Drives the date display in reports and other outputs. Optional -->
		<display_time_zone   id="${JEYZER_DISPLAY_TIME_ZONE_ID}"/>
		
	</time_zones>

	<!-- Static data setup -->
	<setup setup_config_file="${JEYZER_ANALYZER_CONFIG_DIR}/setup/default_setup.xml"/>

</analysis>
