<?xml version="1.0" encoding="UTF-8"?>

<profile name="Hadoop" version="2.8">

		<!-- 
			Pattern rule appliance by priority :
			0 - locker (1004)
			1 - stack_size_interest (1003)
			2 - exclude_thread_name (1002)
			3 - exclude (1001)
			4 - locker  (7)
			5 - function  (6)
			6 - function_discovery  (5)
			7 - executor  (4)
			8 - executor_thread_name (3)
			9 - operation (2)
			10 - operation_discovery (1)
			Exclude, function, operation and executor patterns priorities can be overriden by pattern attribute.
	 	-->
		<patterns>
			<!-- In pattern attribute, use semicolon separator to declare multiple line patterns -->
			<functions>
				<function pattern="org.apache.hadoop.hdfs.DistributedFileSystem.open" name="Hadoop open distributed file"/>
				<function pattern="org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse" name="Receive RCP response"/>
				<function pattern="org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields" name="Read pipeline ack fields"/>
			</functions>
			<operations>
				<!-- Operation patterns apply for the first 20 lines of the thread dump                	 -->
				<!-- Exception : patterns ending with '.' apply for the first 2 lines of the thread dump -->
				<operation pattern="org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations" name="Get block locations"/>
			</operations>
			<lockers>
				<!-- Locker patterns apply for the first 20 lines of the thread dump                 -->
  				<!-- locker pattern="java.util.concurrent.locks.LockSupport.park" name="LockSupport"/-->
			</lockers>
			<executors>
				<!-- Executor patterns must be available within the 20 first lines of the thread dump -->
				<executor pattern="org.apache.hadoop.ipc.Client$Connection.run" name="Hadoop IPC client"/>
			</executors>
			<executor_thread_names>
				<!-- Executor pattern based on the thread name. Regular expression recommended -->
				<executor_thread_name pattern="ResponseProcessor for block BP" name="Hadoop block resp processor"/>
			</executor_thread_names>
			<excludes>
				<!-- If stack size is equal or below the limit (optional size attribute), thread stack is excluded -->
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly;java.util.concurrent.Semaphore.acquire;org.apache.hadoop.hbase.ipc.FastPathBalancedQueueRpcExecutor$FastPathHandler.getCallRunner" name="Hadoop fast path handler waiting"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.LinkedBlockingQueue.take;org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.getCallRunner;org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run" name="RpcExecutor waiting"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.LinkedBlockingQueue.take;org.apache.hadoop.hbase.regionserver.wal.FSHLog$SyncRunner.run" name="FSHLog waiting"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;org.apache.hadoop.hbase.util.StealJobQueue.take" name="Steal job queue waiting"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.ArrayBlockingQueue.take;org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.getRAMQueueEntries" name="Bucket Cache waiting for RAM entries"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos;java.util.concurrent.DelayQueue.poll;java.util.concurrent.DelayQueue.poll;org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run" name="MemStoreFlusher waiting"/>
				<exclude pattern="java.lang.Object.wait;org.apache.hadoop.hbase.io.hfile.LruBlockCache$EvictionThread.run" name="LruBlockCache EvictionThread waiting"/>
				<exclude pattern="java.lang.Thread.sleep;org.apache.hadoop.hbase.regionserver.LeaseManager.run" name="LeaseManager sleeping"/>
				<exclude pattern="java.lang.Thread.sleep;org.apache.hadoop.hbase.monitoring.TaskMonitor$MonitorRunnable.run" name="TaskMonitor MonitorRunnable sleeping"/>
				<exclude pattern="java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill;java.util.concurrent.SynchronousQueue$TransferStack.transfer;java.util.concurrent.SynchronousQueue.poll;org.apache.hbase.thirdparty.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait" name="ReservedThreadExecutor ReservedThread wait"/>
				<exclude pattern="java.lang.Object.wait;org.apache.hadoop.ipc.Client$Connection.waitForWork;org.apache.hadoop.ipc.Client$Connection.run" name="Hadoop client wait for work"/>
				<exclude pattern="java.lang.Object.wait;org.apache.hadoop.hdfs.DataStreamer.run" name="Data streamer wait"/>
				<exclude pattern="java.lang.Object.wait;org.apache.hadoop.hbase.util.Sleeper.sleep;org.apache.hadoop.hbase.util.Sleeper.sleep;org.apache.hadoop.hbase.regionserver.HRegionServer.run" name="HRegionServer sleep"/>
				<exclude pattern="java.lang.Thread.join;org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start;org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run;org.apache.hadoop.util.ToolRunner.run;org.apache.hadoop.hbase.util.ServerCommandLine.doMain" name="ServerCommandLine main waiting"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.LinkedBlockingQueue.take;org.apache.hadoop.hbase.regionserver.RemoteProcedureResultReporter.run" name="RemoteProcedureResultReporter waiting"/>
				<exclude pattern="java.lang.Thread.sleep;org.apache.hadoop.hbase.util.JvmPauseMonitor$Monitor.run" name="JvmPauseMonitor sleeping"/>
				<exclude pattern="java.lang.Object.wait;org.apache.hadoop.hbase.wal.AbstractWALRoller.run" name="AbstractWALRoller waiting"/>
				<exclude pattern="org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0;org.apache.hadoop.net.unix.DomainSocketWatcher.access$900;org.apache.hadoop.net.unix.DomainSocketWatcher$2.run" name="Unix DomainSocketWatcher polling"/>
				<exclude pattern="java.lang.Thread.sleep;org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run" name="LeaseRenewer sleeping"/>
				<!-- Zookeeper -->
				<exclude pattern="java.lang.Thread.sleep;org.apache.zookeeper.Login$1.run" name="Zookeeper login sleeping"/>
				<exclude pattern="sun.nio.ch.SelectorImpl.lockAndDoSelect;sun.nio.ch.SelectorImpl.select;org.apache.zookeeper.ClientCnxnSocketNIO.doTransport;org.apache.zookeeper.ClientCnxn$SendThread.run" name="Zookeeper ClientCnxnSocketNIO sender select"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.LinkedBlockingQueue.take;org.apache.zookeeper.ClientCnxn$EventThread.run" name="Zookeeper ClientCnxn event select"/>
				<exclude pattern="java.lang.Object.wait;org.apache.hadoop.hbase.zookeeper.ZKLeaderManager.waitToBecomeLeader;org.apache.hadoop.hbase.security.token.AuthenticationTokenSecretManager$LeaderElector.run" name="Zookeeper LeaderElector wait"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos;java.util.concurrent.DelayQueue.poll;org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient.run" name="Zookeeper ReadOnlyZKClient polling"/>
				<!-- Ranger -->
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos;java.util.concurrent.ArrayBlockingQueue.poll;org.apache.ranger.audit.queue.AuditBatchQueue.runLogAudit;org.apache.ranger.audit.queue.AuditBatchQueue.run" name="Ranger AuditBatchQueue polling"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos;java.util.concurrent.LinkedBlockingQueue.poll;org.apache.ranger.audit.queue.AuditFileSpool.runLogAudit;org.apache.ranger.audit.queue.AuditFileSpool.run" name="Ranger AuditFileSpool polling"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos;java.util.concurrent.LinkedBlockingQueue.poll;org.apache.ranger.audit.queue.AuditSummaryQueue.runLogAudit;org.apache.ranger.audit.queue.AuditSummaryQueue.run" name="Ranger AuditSummaryQueue polling"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.LinkedBlockingQueue.take;org.apache.ranger.plugin.contextenricher.RangerTagEnricher$RangerTagRefresher.run" name="Ranger RangerTagEnricher RangerTagRefresher waiting to take"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.LinkedBlockingQueue.take;org.apache.ranger.audit.queue.AuditAsyncQueue.runLogAudit;org.apache.ranger.audit.queue.AuditAsyncQueue.run" name="Ranger AuditAsyncQueue waiting to take"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.LinkedBlockingQueue.take;org.apache.ranger.plugin.util.PolicyRefresher.run" name="Ranger PolicyRefresher waiting to take"/>
				<exclude pattern="java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly;java.util.concurrent.Semaphore.acquire;org.apache.ranger.audit.provider.AuditProviderFactory$RangerAsyncAuditCleanup.run" name="Ranger RangerAsyncAuditCleanup semaphore"/>
			</excludes>
			<exclude_thread_names>
				<!-- Exclude stack based on thread name. Regular expression based recommended -->
				<!-- If stack size is equal or below the limit (optional size attribute), thread stack is excluded -->
				<!-- exclude_thread_name pattern_regex="RMI TCP.*" name="RMI"/-->
				<!-- exclude_thread_name pattern="JMX server connection timeout" name="RMI"/-->
				<exclude_thread_name pattern_regex="^org.apache.hadoop.fs.FileSystem\$Statistics\$StatisticsDataReferenceCleaner" name="Hadoop cleanup thread" size="5"/>
			</exclude_thread_names>
		</patterns>

</profile>
